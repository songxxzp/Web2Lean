import requests

VLLM_BASE_URL = "http://localhost:8000/v1"
MODEL_PATH = "/root/Kimina-Autoformalizer-7B"

def interactive_chat_v2():
    print("ğŸš€ VLLM äº¤äº’å¼å·¥å…· (ä½¿ç”¨ /v1/chat/completions æ¥å£)")
    
    while True:
        user_input = input("\nğŸ“ è¯·è¾“å…¥æ•°å­¦é—®é¢˜ (è¾“å…¥ quit é€€å‡º): ")
        if user_input.lower() in ['exit', 'quit']: break

        # ç›´æ¥æ„é€  messages åˆ—è¡¨ (æ— éœ€ä½¿ç”¨æœ¬åœ°çš„ AutoTokenizer)
        messages = [
            {"role": "system", "content": "You are an expert in mathematics and Lean 4."},
            {"role": "user", "content": f"Please autoformalize the following problem in Lean 4 with a header. Use the following theorem names: my_favorite_theorem.\n\n{user_input}"}
        ]
        
        # æ„é€ è¯·æ±‚ä½“
        payload = {
            "model": MODEL_PATH, 
            "messages": messages,   # <-- ç›´æ¥å‘é€æ¶ˆæ¯åˆ—è¡¨
            "max_tokens": 2048,
            "temperature": 0.6
        }

        try:
            # è®¿é—® chat/completions è·¯å¾„
            response = requests.post(f"{VLLM_BASE_URL}/chat/completions", json=payload)
            response.raise_for_status() # æ£€æŸ¥ 4XX/5XX é”™è¯¯
            
            res_json = response.json()
            
            # æå– chat completions çš„ç»“æœ
            output_text = res_json['choices'][0]['message']['content']
            
            print("\nâœ¨ **Lean 4 ç»“æœ**:")
            print("---")
            print(output_text)
            print("---")
            
        except requests.exceptions.HTTPError as e:
            print(f"âŒ HTTP é”™è¯¯ (è¯·ç¡®è®¤ Server çŠ¶æ€åŠ Model ID): {e}")
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")

if __name__ == "__main__":
    interactive_chat_v2()